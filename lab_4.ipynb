{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b38396-4691-413b-9856-edd71a08c288",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab4 Intro\n",
    "Now that you have classified the Voice of Customers into categories in the previous experiment, you can use Generative AI techniques to write narratives for you further.\n",
    "\n",
    "### Your objectives are:\n",
    "\n",
    "- Explore the statistical results of classification\n",
    "- Write narratives for the summary analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885f205-3b90-4d03-8c9d-0e763047c192",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f625de-1ca3-4167-a158-2628994ff090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq boto3 langchain==0.2.16 langchain_aws==0.1.17 pandas openpyxl termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a39f8-d017-4bd3-b289-dab163db7da2",
   "metadata": {},
   "source": [
    "## 2. Initialize Bedrock model using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80647c-214f-4b5b-bea1-5676af790fc3",
   "metadata": {},
   "source": [
    "- We use [Langchain](https://www.langchain.com/) SDK to build the application\n",
    "- Initialize a ChatBedrock object with Amzon Titan Text model, the model id is \"amazon.titan-text-premier-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbdffc5-9fd0-40f9-b142-5c609dcad122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser,XMLOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate\n",
    "\n",
    "model_id = \"amazon.titan-text-premier-v1:0\" \n",
    "llm = ChatBedrock( model_id=model_id,\n",
    "                  streaming=True,\n",
    "                callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                model_kwargs=dict(temperature=0.0,maxTokenCount=3072)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f18fa1-aa33-4585-956f-697225850adc",
   "metadata": {},
   "source": [
    "- test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e72624-2669-441e-92b4-ade4d14229a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je suis amoureux de la programmation.', additional_kwargs={'usage': {'prompt_tokens': 23, 'completion_tokens': 12, 'total_tokens': 35}, 'stop_reason': 'FINISH', 'model_id': 'amazon.titan-text-premier-v1:0'}, response_metadata={'usage': {'prompt_tokens': 23, 'completion_tokens': 12, 'total_tokens': 35}, 'stop_reason': 'FINISH', 'model_id': 'amazon.titan-text-premier-v1:0'}, id='run-de1aa08e-01d3-4941-93ae-a3ed642f2338-0', usage_metadata={'input_tokens': 23, 'output_tokens': 12, 'total_tokens': 35})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de2c96-c8ec-486a-ac7d-07e792132184",
   "metadata": {},
   "source": [
    "## 3. Explore statistical results of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10536914-c87c-4677-b181-7751aec0cb60",
   "metadata": {},
   "source": [
    "### Load the customer review data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce8465-7a4e-4bbf-8f0f-bb685b1cc7dd",
   "metadata": {},
   "source": [
    "- Load the examples data to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c89b0f-6b0b-4bd1-b92e-49acceb710c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd087dc-4da6-4418-8109-9c395abec3d3",
   "metadata": {},
   "source": [
    "- Create a langchain chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53018dbe-a33e-4d98-936c-760f520b2631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate([\n",
    "    ('system',system),\n",
    "    ('user',user),\n",
    "    ],\n",
    "    partial_variables={'tags':categories['mappings'].values}\n",
    ")\n",
    "chain = prompt | llm | XMLOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de4ac3-debe-4236-8bbc-aa0bd04078a0",
   "metadata": {},
   "source": [
    "- convert the comments to data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeca0a7-df9f-46aa-a0f5-109505e1166e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
